# ğŸ  House Price Prediction | Advanced Regression Techniques

## ğŸ“Œ Project Overview  

The **House Prices: Advanced Regression Techniques** competition on Kaggle challenges participants to predict house prices based on a rich dataset of housing features. This project focuses on **data analysis, preprocessing pipelines, model selection, and ensemble learning techniques** to maximize prediction accuracy.  

---

## ğŸš€ Key Features  

### ğŸ” 1. Task Analysis  
âœ”ï¸ In-depth exploration of the dataset structure, input features, and target variable.  
âœ”ï¸ Understanding key variables affecting house prices.  

### ğŸ› ï¸ 2. Data Preparation  
âœ”ï¸ **Handling Missing Values:**  
   - Categorical variables filled with `"None"` to preserve category integrity.  
âœ”ï¸ **Feature Transformation:**  
   - **Categorical Features:** One-Hot Encoding.  
   - **Numerical Features:** Standardization for better model performance.  
âœ”ï¸ **Data Splitting:**  
   - Created **training** and **validation** sets for model evaluation.  

### ğŸ”„ 3. Automated Pipelines  
âœ”ï¸ **Pipeline for Numerical Features:** Standardization.  
âœ”ï¸ **Pipeline for Categorical Features:** One-Hot Encoding.  
âœ”ï¸ Integrated pipelines with models for seamless training workflow.  

### ğŸ§  4. Model Building & Hyperparameter Tuning  
âœ”ï¸ **Baseline Model:** Linear Regression.  
âœ”ï¸ **Advanced Regression Models:**  
   - **GridSearchCV & RandomizedSearchCV** applied to:  
     - Ridge Regression  
     - RandomForestRegressor  
     - XGBRegressor  
     - GradientBoostingRegressor  
     - LGBMRegressor  
     - CatBoostRegressor  

### ğŸ”— 5. Advanced Ensemble Learning  
âœ”ï¸ **Voting Regressor:** Combines multiple models for improved predictions.  
âœ”ï¸ **Stacking Regressor:** Uses base models with a meta-model for final prediction.  

---

## ğŸ—ï¸ Project Structure

```bash
MNIST/
â”œâ”€â”€ ğŸ“ input/              
â”‚   â”œâ”€â”€ ğŸ“„ data_description.txt        
â”‚   â”œâ”€â”€ ğŸ“„ sample_submission.csv       # Sample submission 
â”‚   â”œâ”€â”€ ğŸ“„ test.csv                    # Test dataset
â”‚   â””â”€â”€ ğŸ“„ train.csv                   # Training dataset
â”‚
â”œâ”€â”€ ğŸ“ notebooks/                      # Jupyter notebooks
â”‚   â””â”€â”€ ğŸ“˜ HS_01_House Prices.ipynb    # Complete analysis
â”‚
â””â”€â”€ ğŸ“ output/                         
     â””â”€â”€ ğŸ“„ submission_HS_01.csv       # submission predict

```
---

## ğŸ› ï¸ Technologies & Tools  

| Category             | Tools / Libraries |
|----------------------|------------------|
| **Programming**      | Python 3.8+ |
| **Data Processing**  | Pandas, NumPy |
| **Machine Learning** | Scikit-learn, XGBoost, LightGBM, CatBoost |
| **Visualization**    | Matplotlib, Seaborn |

---

### ğŸ† Results
**Achieved Top 844** on Kaggle leaderboard using stacked ensemble models.

---